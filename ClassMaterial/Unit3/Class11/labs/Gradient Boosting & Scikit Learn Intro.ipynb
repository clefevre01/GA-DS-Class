{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting & Scikit-Learn Intro\n",
    "\n",
    "This lab is designed to give everyone their first introduction to the Scikit-Learn API, and Gradient Boosting, one of the most powerful techniques in predictive modeling.\n",
    "\n",
    "During this lab you'll see if you can build a model, understand its working parts, and make improvements to your results!  \n",
    "\n",
    "The great thing about `Scikit Learn` is that its API is almost identical from one algorithm to another, so once you get the hang of how to use it, using different methods is fairly seamless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Load in the `housing.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/cameronlefevre/Test-Repo/ClassMaterial/Unit3/data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Randomly shuffle your dataset using the `shuffle` method, using a `random_state` of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(df.shape[0], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Declare your `X` & `y` variables -- We'll be predicting price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('PRICE', axis=1) #everything but the PRICE column\n",
    "y = df['PRICE'] # just the PRICE column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Create a training and test set.\n",
    "\n",
    "The training set will be the first 80% of the dataset (for both `X` & `y`), and test set will be the last 20%.  Do this for both `X` & `y`, using your shuffled data.\n",
    "\n",
    "Subsequent questions will refer to the variables you created in this step as `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "cutoff = int(df.shape[0]*.8)\n",
    "\n",
    "X_train, X_test = X[:cutoff].copy(), X[cutoff:].copy()\n",
    "y_train, y_test  = y[:cutoff].copy(), y[cutoff:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Import `GradientBoostingRegressor` and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Call the `fit()` method on `X_train` & `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Make a column that represents the predictions your model made for each sample in your original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prediction'] = gbm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Check the score of your model using the `score()` method.  Compare your score on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9790704008575339, Test Score: 0.8948584148190182\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "print(f\"Train score: {gbm.score(X_train, y_train)}, Test Score: {gbm.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9:** Take a look at the values returned from the `feature_importances_` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.32570653e-02, 5.22216082e-05, 1.76244557e-03, 5.42716264e-04,\n",
       "       2.74667859e-02, 3.54431976e-01, 6.10631402e-03, 6.66084781e-02,\n",
       "       1.16943296e-03, 1.72096601e-02, 2.48807624e-02, 1.50372093e-02,\n",
       "       4.61474933e-01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10:** To make a bit more sense out of these, let's put these values into a more readable format.  \n",
    "\n",
    "Try making a 2 column dataframe using `X.columns` and the values from `feature_importances_` (they should correspond to one another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.461475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>0.354432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>0.066608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>0.027467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.024881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>0.017210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.015037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.006106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.001762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Column  Importance\n",
       "12    LSTAT    0.461475\n",
       "5        RM    0.354432\n",
       "7       DIS    0.066608\n",
       "4       NOX    0.027467\n",
       "10  PTRATIO    0.024881\n",
       "0      CRIM    0.023257\n",
       "9       TAX    0.017210\n",
       "11        B    0.015037\n",
       "6       AGE    0.006106\n",
       "2     INDUS    0.001762\n",
       "8       RAD    0.001169\n",
       "3      CHAS    0.000543\n",
       "1        ZN    0.000052"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "importances = pd.DataFrame({\n",
    "    'Column': X.columns,\n",
    "    'Importance': gbm.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.Importance.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11:** Can you improve your results?  For now, toy around a little bit with a few different options for getting different results.  These could be any of the following:\n",
    "\n",
    " - changing the number of boosting rounds used via `n_estimators`\n",
    " - changing the learning rate\n",
    " - removing columns that have lower feature importance, or very low correlation with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators  = [100, 250, 500]\n",
    "learning_rate = [.05, .1]\n",
    "tree_depth    = [3, 4, 5, 6]\n",
    "cv_scores     = []\n",
    "\n",
    "for estimators in n_estimators:\n",
    "    for rate in learning_rate:\n",
    "        for depth in tree_depth:\n",
    "#            print(f\"Fitting model for: {}\")\n",
    "            gbm.set_params(n_estimators=estimators, learning_rate=rate, max_depth=depth)\n",
    "            gbm.fit(X_train, y_train)\n",
    "            cv_scores.append((gbm.score(X_test, y_test), estimators, rate, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8786266782877534, 100, 0.05, 3),\n",
       " (0.8895933869375947, 100, 0.05, 4),\n",
       " (0.904354768986493, 100, 0.05, 5),\n",
       " (0.9047742644081224, 100, 0.05, 6),\n",
       " (0.8943649457006226, 100, 0.1, 3),\n",
       " (0.9011665051447878, 100, 0.1, 4),\n",
       " (0.9038117240279105, 100, 0.1, 5),\n",
       " (0.9058348999619341, 100, 0.1, 6),\n",
       " (0.8953784292938393, 250, 0.05, 3),\n",
       " (0.9028309253811327, 250, 0.05, 4),\n",
       " (0.9083021661313042, 250, 0.05, 5),\n",
       " (0.9102231546133156, 250, 0.05, 6),\n",
       " (0.8996792225628538, 250, 0.1, 3),\n",
       " (0.9091086823941428, 250, 0.1, 4),\n",
       " (0.8902087462990661, 250, 0.1, 5),\n",
       " (0.9053818869054743, 250, 0.1, 6),\n",
       " (0.9065528203580262, 500, 0.05, 3),\n",
       " (0.8944539040959828, 500, 0.05, 4),\n",
       " (0.9034971562085208, 500, 0.05, 5),\n",
       " (0.9152351612701669, 500, 0.05, 6),\n",
       " (0.9041827844272571, 500, 0.1, 3),\n",
       " (0.9063886572563367, 500, 0.1, 4),\n",
       " (0.9037174096269587, 500, 0.1, 5),\n",
       " (0.9041013929844511, 500, 0.1, 6)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
