{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraper Lab Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connecting to Data And Initializing the Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1, length of titles list: 30\n",
      "Round: 2, length of titles list: 30\n",
      "Round: 3, length of titles list: 30\n",
      "Round: 4, length of titles list: 30\n",
      "Round: 5, length of titles list: 30\n",
      "Round: 6, length of titles list: 30\n",
      "Round: 7, length of titles list: 30\n",
      "Round: 8, length of titles list: 30\n",
      "Round: 9, length of titles list: 0\n",
      "Round: 10, length of titles list: 0\n"
     ]
    }
   ],
   "source": [
    "titles_list = []\n",
    "i = 0\n",
    "num_round = 1\n",
    "looping = True\n",
    "\n",
    "while looping:\n",
    "    url = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req = requests.get(url)\n",
    "    scraper = BeautifulSoup(req.text)\n",
    "    titles = scraper.find_all('a', {'class': 'lemon--a__373c0__IEZFH', 'class': 'link__373c0__1G70M',\n",
    "                                    'class': 'link-color--inherit__373c0__3dzpk',\n",
    "                                    'class':  'link-size--inherit__373c0__1VFlE'})\n",
    "    titles = [str(title) for title in titles]\n",
    "    titles = [title.replace('</a>', '') for title in titles]\n",
    "    titles = [title.split('>')[1] for title in titles]\n",
    "    titles = [title for title in titles if title != 'more' and '<div' not in title and '<span' not in title]\n",
    "    print(f'Round: {num_round}, length of titles list: {len(titles)}')\n",
    "    titles_list.extend(titles)\n",
    "    i += 30\n",
    "    num_round += 1\n",
    "    if len(titles) == 0:\n",
    "        looping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1, length of num_reviews list: 30\n",
      "Round: 2, length of num_reviews list: 30\n",
      "Round: 3, length of num_reviews list: 30\n",
      "Round: 4, length of num_reviews list: 30\n",
      "Round: 5, length of num_reviews list: 30\n",
      "Round: 6, length of num_reviews list: 30\n",
      "Round: 7, length of num_reviews list: 30\n",
      "Round: 8, length of num_reviews list: 30\n",
      "Round: 9, length of num_reviews list: 0\n"
     ]
    }
   ],
   "source": [
    "looping   = True\n",
    "num_round = 1\n",
    "i = 0\n",
    "reviews_list = []\n",
    "\n",
    "while looping:\n",
    "    url         = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req         = requests.get(url)\n",
    "    scraper     = BeautifulSoup(req.text)\n",
    "    num_reviews = scraper.find_all('span', {'class': 'lemon--span__373c0__3997G', \n",
    "                                        'class': 'text__373c0__2Kxyz',\n",
    "                                        'class': 'reviewCount__373c0__2r4xT',\n",
    "                                        'class': 'text-color--black-extra-light__373c0__2OyzO'})\n",
    "    num_reviews = [str(review) for review in num_reviews]\n",
    "    num_reviews = [review.replace('</span>', '') for review in num_reviews]\n",
    "    num_reviews = [review.split('>')[1] for review in num_reviews]\n",
    "    num_reviews = [review for review in num_reviews if review.isdigit()]\n",
    "    print(f'Round: {num_round}, length of num_reviews list: {len(num_reviews)}')\n",
    "    reviews_list.extend(num_reviews)\n",
    "    i += 30\n",
    "    num_round += 1\n",
    "    if len(num_reviews) == 0:\n",
    "        looping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Round 1, Length of prices list: 30\n",
      "Finishing Round 2, Length of prices list: 30\n",
      "Finishing Round 3, Length of prices list: 0\n"
     ]
    }
   ],
   "source": [
    "looping   = True\n",
    "num_round = 1\n",
    "i = 0\n",
    "prices_list = []\n",
    "\n",
    "while looping:\n",
    "    url          = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req          = requests.get(url)\n",
    "    scraper      = BeautifulSoup(req.text)\n",
    "    price_ranges = scraper.find_all('span', {'class': 'lemon--span__373c0__3997G', \n",
    "                                        'class': 'text__373c0__2Kxyz',\n",
    "                                        'class': 'reviewCount__373c0__2r4xT',\n",
    "                                        'class': 'text-color--black-extra-light__373c0__2OyzO'})\n",
    "    parent_body  = scraper.find_all('div', {'class': 'container__373c0__3HMKB'})\n",
    "    price_ranges = [str(range_) for range_ in price_ranges]\n",
    "    price_ranges = [range_.replace('</span>', '') for range_ in price_ranges]\n",
    "    price_ranges = [range_.split('>')[1] for range_ in price_ranges]\n",
    "    price_ranges = [range_ for range_ in price_ranges if '\\xA3' in range_]\n",
    "    if len(price_ranges) < 30:\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            if '\\xA3' not in scraper_tag.text:\n",
    "                price_ranges.insert(idx, None)\n",
    "    prices_list.extend(price_ranges)\n",
    "    print(f\"Finishing Round {num_round}, Length of prices list: {len(price_ranges)}\")\n",
    "    i += 30\n",
    "    num_round += 1\n",
    "    if len(price_ranges) == 0:\n",
    "        looping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Telephone Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Round 1, Length of phone_numbers: 30\n",
      "Finishing Round 2, Length of phone_numbers: 30\n",
      "Finishing Round 3, Length of phone_numbers: 30\n",
      "Finishing Round 4, Length of phone_numbers: 30\n",
      "Finishing Round 5, Length of phone_numbers: 0\n"
     ]
    }
   ],
   "source": [
    "looping   = True\n",
    "num_round = 1\n",
    "i = 0\n",
    "telephone_list = []\n",
    "\n",
    "while looping:\n",
    "    url           = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req           = requests.get(url)\n",
    "    scraper       = BeautifulSoup(req.text)\n",
    "    phone_numbers = scraper.find_all('p', {'class': 'lemon--p__373c0__3Qnnj', \n",
    "                                        'class': 'text__373c0__2Kxyz',\n",
    "                                        'class': 'text-color--black-extra-light__373c0__2OyzO',\n",
    "                                        'class': 'text-align--right__373c0__1f0KI',\n",
    "                                        'class': 'text-size--small__373c0__3NVWO'})\n",
    "    phone_numbers = [str(item) for item in phone_numbers]\n",
    "    phone_numbers = [item.replace('</p>', '') for item in phone_numbers]\n",
    "    phone_numbers = [item.split('>')[1] for item in phone_numbers]\n",
    "    phone_numbers = [item for item in phone_numbers if item.replace(' ', '').isdigit()]\n",
    "    if len(phone_numbers) < 30:\n",
    "        parent_body   = scraper.find_all('div', {'class': 'container__373c0__3HMKB'})\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            has_phone_number = any(len(item) >= 4 and item.replace('-', '').isdigit() for item in scraper_tag.text.split())\n",
    "            if not has_phone_number:\n",
    "                phone_numbers.insert(idx, None)\n",
    "    telephone_list.extend(phone_numbers)\n",
    "    print(f\"Finishing Round {num_round}, Length of phone_numbers: {len(phone_numbers)}\")\n",
    "    i += 30\n",
    "    num_round += 1\n",
    "    if len(phone_numbers) == 0:\n",
    "        looping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no more reviews, breaking\n"
     ]
    }
   ],
   "source": [
    "looping   = True\n",
    "num_round = 1\n",
    "i = 0\n",
    "reviews_list = []\n",
    "\n",
    "while looping:\n",
    "\n",
    "    url           = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req           = requests.get(url)\n",
    "    scraper       = BeautifulSoup(req.text)\n",
    "    reviews       = scraper.find_all('p', {'class': 'text-color--black-extra-light__373c0__2OyzO',\n",
    "                                           'class': 'text-align--left__373c0__2XGa-'})\n",
    "    \n",
    "    reviews = [str(review) for review in reviews]\n",
    "    reviews = [review.split('<span')[0] for review in reviews]\n",
    "    reviews = [review.split('>')[1] for review in reviews]\n",
    "    reviews = [review for review in reviews if '</p' not in review]\n",
    "    reviews = [review for review in reviews if '<a' not in review and len(review.split()) > 5]\n",
    "    reviews = reviews[:-1]\n",
    "    \n",
    "    if len(reviews) == 0:\n",
    "        print(\"Found no more reviews, breaking\")\n",
    "        break\n",
    "    \n",
    "    if len(reviews) < 30:\n",
    "        parent_body   = scraper.find_all('div', {'class': 'container__373c0__3HMKB'})\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            if '\\xA0more' not in scraper_tag.text:\n",
    "                reviews.insert(idx, None)\n",
    "\n",
    "    print(f\"Finished Round {num_round}, number of reviews {len(reviews)}\")\n",
    "    i += 30\n",
    "    num_round += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 1, found 30 primary values\n",
      "Did not return any values, stopping the loop.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "num_round = 1\n",
    "category_one_master = []\n",
    "category_two_master = []\n",
    "category_three_master = []\n",
    "looping = True\n",
    "\n",
    "while looping:\n",
    "    url = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req = requests.get(url)\n",
    "    scraper = BeautifulSoup(req.content)\n",
    "\n",
    "    parent_body  = scraper.find_all('div',  class_='container__09f24__21w3G')\n",
    "    if len(parent_body) == 0:\n",
    "        looping = False\n",
    "        print(\"Did not return any values, stopping the loop.\")\n",
    "        break\n",
    "    link_groups = [body.find_all('a', href=True) for body in parent_body]\n",
    "    categories = []\n",
    "    for group in link_groups:\n",
    "        food_type = []\n",
    "        for link in group:\n",
    "            if 'find_desc' in link['href']:\n",
    "                food_type.append(link.text)\n",
    "        categories.append(food_type)\n",
    "    category_one = []\n",
    "    category_two = []\n",
    "    category_three = []\n",
    "\n",
    "    for category in categories:\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                try:\n",
    "                    category_one.append(category[i])\n",
    "                except:\n",
    "                    category_one.append(None)\n",
    "            if i == 1:\n",
    "                try:\n",
    "                    category_two.append(category[i])\n",
    "                except:\n",
    "                    category_two.append(None)\n",
    "            if i == 2:\n",
    "                try:\n",
    "                    category_three.append(category[i])\n",
    "                except:\n",
    "                    category_three.append(None)\n",
    "                    \n",
    "    category_one_master.extend(category_one)\n",
    "    category_two_master.extend(category_two)\n",
    "    category_three_master.extend(category_three)\n",
    "    print(f'Finished round {num_round}, found {len(category_one)} primary values')\n",
    "    i += 30\n",
    "    num_round += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the connection was blocked for some reason (which some websites will do if you make too many in a short period of time), it is probably best to wrap this up in a single loop, that way you'll always be developing data from the different tags in a consistent way.  \n",
    "\n",
    "Doing so would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing returned, breaking\n"
     ]
    }
   ],
   "source": [
    "looping   = True\n",
    "num_round = 1\n",
    "i = 0\n",
    "titles_list = []\n",
    "num_reviews_list = []\n",
    "telephone_list = []\n",
    "prices_list = []\n",
    "reviews_list = []\n",
    "category_one_master = []\n",
    "category_two_master = []\n",
    "category_three_master = []\n",
    "\n",
    "while looping:\n",
    "    url           = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C+United+Kingdom&ns=1&start={i}'\n",
    "    req           = requests.get(url)\n",
    "    scraper       = BeautifulSoup(req.text)\n",
    "    \n",
    "    # code for getting the titles\n",
    "    titles = scraper.find_all('a', {'class': 'lemon--a__373c0__IEZFH', 'class': 'link__373c0__1G70M',\n",
    "                                    'class': 'link-color--inherit__373c0__3dzpk',\n",
    "                                     'class':  'link-size--inherit__373c0__1VFlE'})\n",
    "    titles = [str(title) for title in titles]\n",
    "    titles = [title.replace('</a>', '') for title in titles]\n",
    "    titles = [title.split('>')[1] for title in titles]\n",
    "    titles = [title for title in titles if title != 'more' and '<div' not in title and '<span' not in title]\n",
    "    titles_list.extend(titles)\n",
    "    \n",
    "    num_reviews = scraper.find_all('span', {'class': 'lemon--span__373c0__3997G', \n",
    "                                        'class': 'text__373c0__2Kxyz',\n",
    "                                        'class': 'reviewCount__373c0__2r4xT',\n",
    "                                        'class': 'text-color--black-extra-light__373c0__2OyzO'})\n",
    "    \n",
    "    # code for getting the number of reviews\n",
    "    num_reviews = [str(review) for review in num_reviews]\n",
    "    num_reviews = [review.replace('</span>', '') for review in num_reviews]\n",
    "    num_reviews = [review.split('>')[1] for review in num_reviews]\n",
    "    num_reviews = [review for review in num_reviews if review.isdigit()]\n",
    "    num_reviews_list.extend(num_reviews)    \n",
    "    \n",
    "    # code for the price ranges\n",
    "    price_ranges = scraper.find_all('span', {'class': 'lemon--span__373c0__3997G', \n",
    "                                    'class': 'text__373c0__2Kxyz',\n",
    "                                    'class': 'reviewCount__373c0__2r4xT',\n",
    "                                    'class': 'text-color--black-extra-light__373c0__2OyzO'})\n",
    "    parent_body  = scraper.find_all('div', {'class': 'container__09f24__21w3G'})\n",
    "    price_ranges = [str(range_) for range_ in price_ranges]\n",
    "    price_ranges = [range_.replace('</span>', '') for range_ in price_ranges]\n",
    "    price_ranges = [range_.split('>')[1] for range_ in price_ranges]\n",
    "    price_ranges = [range_ for range_ in price_ranges if '\\xA3' in range_]\n",
    "    if len(price_ranges) < 30:\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            if '\\xA3' not in scraper_tag.text:\n",
    "                price_ranges.insert(idx, None)\n",
    "    prices_list.extend(price_ranges)\n",
    "    \n",
    "    # code for the telephone numbers\n",
    "    phone_numbers = scraper.find_all('p', {'class': 'lemon--p__373c0__3Qnnj', \n",
    "                                        'class': 'text__373c0__2Kxyz',\n",
    "                                        'class': 'text-color--black-extra-light__373c0__2OyzO',\n",
    "                                        'class': 'text-align--right__373c0__1f0KI',\n",
    "                                        'class': 'text-size--small__373c0__3NVWO'})\n",
    "    phone_numbers = [str(item) for item in phone_numbers]\n",
    "    phone_numbers = [item.replace('</p>', '') for item in phone_numbers]\n",
    "    phone_numbers = [item.split('>')[1] for item in phone_numbers]\n",
    "    phone_numbers = [item for item in phone_numbers if item.replace(' ', '').isdigit()]\n",
    "    if len(phone_numbers) < 30:\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            has_phone_number = any(len(item) >= 4 and item.replace('-', '').isdigit() for item in scraper_tag.text.split())\n",
    "            if not has_phone_number:\n",
    "                phone_numbers.insert(idx, None)\n",
    "    telephone_list.extend(phone_numbers)\n",
    "    \n",
    "    # code for getting the reviews\n",
    "    reviews = scraper.find_all('p', {'class': 'text-color--black-extra-light__373c0__2OyzO',\n",
    "                                           'class': 'text-align--left__373c0__2XGa-'})\n",
    "    \n",
    "    reviews = [str(review) for review in reviews]\n",
    "    reviews = [review.split('<span')[0] for review in reviews]\n",
    "    reviews = [review.split('>')[1] for review in reviews]\n",
    "    reviews = [review for review in reviews if '</p' not in review]\n",
    "    reviews = [review for review in reviews if '<a' not in review and len(review.split()) > 5]\n",
    "    reviews = reviews[:-1]\n",
    "    \n",
    "    if len(reviews) < 30:\n",
    "        for idx, scraper_tag in enumerate(parent_body):\n",
    "            if '\\xA0more' not in scraper_tag.text:\n",
    "                reviews.insert(idx, None)\n",
    "    reviews_list.extend(reviews)\n",
    "    \n",
    "    link_groups = [body.find_all('a', href=True) for body in parent_body]\n",
    "    categories = []\n",
    "    for group in link_groups:\n",
    "        food_type = []\n",
    "        for link in group:\n",
    "            if 'find_desc' in link['href']:\n",
    "                food_type.append(link.text)\n",
    "        categories.append(food_type)\n",
    "    category_one = []\n",
    "    category_two = []\n",
    "    category_three = []\n",
    "\n",
    "    for category in categories:\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                try:\n",
    "                    category_one.append(category[i])\n",
    "                except:\n",
    "                    category_one.append(None)\n",
    "            if i == 1:\n",
    "                try:\n",
    "                    category_two.append(category[i])\n",
    "                except:\n",
    "                    category_two.append(None)\n",
    "            if i == 2:\n",
    "                try:\n",
    "                    category_three.append(category[i])\n",
    "                except:\n",
    "                    category_three.append(None)\n",
    "                    \n",
    "    category_one_master.extend(category_one)\n",
    "    category_two_master.extend(category_two)\n",
    "    category_three_master.extend(category_three)\n",
    "    \n",
    "    if len(titles) == 0:\n",
    "        looping = False\n",
    "        print(\"Nothing returned, breaking\")\n",
    "        break\n",
    "    print(f\"Finished round {num_round}\")\n",
    "    i += 30\n",
    "    num_round += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'Title': titles_list,\n",
    "    'NumReviews': num_reviews_list,\n",
    "    'Phone': telephone_list,\n",
    "    'PriceRange': prices_list,\n",
    "    'Reviews': reviews_list,\n",
    "    'CategoryOne': category_one_master,\n",
    "    'CategoryTwo': category_two_master,\n",
    "    'CategoryThree': category_three_master\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
